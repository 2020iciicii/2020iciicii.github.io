---
layout: talk
title: "Communication-efficient federated learning"
permalink: /Speech/talk1-9/

---

<div class="talk-container">
    <div class="talk-header">
        <h2>Presenter: Prof. Yaochu Jin</h2>
    </div>
    <h3>Abstract</h3>
    <p>
Federated learning is a distributed machine learning framework that can preserve data privacy. One challenge in federated learning is to reduce the communication cost without significant performance degradation. This talk is going to introduce three recent ideas for communication efficient federated learning, including asynchronous model update and temporally weighted averaging, weight quantization and complexity minimization through neural architecture search. Finally, we discuss ideas of performing real-time neural architecture search in the federated learning framework.
    </p>
    <h3>Biography</h3>
    <p>
Yaochu Jin received the B.Sc., M.Sc., and Ph.D. degrees in automatic control from Zhejiang University, Hangzhou, China, in 1988, 1991, and 1996, respectively, and the Dr.-Ing. degree from Ruhr-University Bochum, Bochum, Germany, in 2001.
    </p>
    <p>
He is a Distinguished Chair Professor in Computational Intelligence, Department of Computer Science, University of Surrey, Guildford, U.K. He was a Finland Distinguished Professor, University of Jyvaskyla, Finland, and a Changjiang Distinguished Visiting Professor, Northeastern University, China. His main research interests include data-driven surrogate-assisted evolutionary optimization, secure machine learning, multi-objective evolutionary learning, swarm robotics, and evolutionary developmental systems.
    </p>
        <p>
Dr Jin is presently the Editor-in-Chief of the IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS and the Editor-in-Chief of Complex & Intelligent Systems. He is named as a Highly Cited Researcher for 2019 and 2020 by Clarivate. He is a Fellow of IEEE.
    </p>
</div>

